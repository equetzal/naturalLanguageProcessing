{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 12\n",
    "- **Alumna:** Enya Quetzalli Gómez Rodríguez *(Eduardo Gómez Rodríguez)*\n",
    "- **Profesora:** Olga Kolesnikova\n",
    "- **Escuela:** Escuela Superior de Cómputo del IPN\n",
    "- **Grupo:** 3CV9\n",
    "- **Semestre:** 2020/2\n",
    "    \n",
    "## Modelo Okapi BM25 para recuperación de información y ranking\n",
    "\n",
    "Supongamos que deseamos realizar una búsqueda *(Ej. Buscar en Google)* de una ***Query*** $Q$ en internet, compuesta por las palabras \"profesores de ESCOM\". Regularmente lo que buscamos es un *documento*, el cuál contiene información relacionada a nuestra búsqueda. Estos documentos pueden ser html, texto plano o una diversidad de formatos que podríamos analizar, en cuyo caso todos los documentos primero deben ser *normalizados* para poder ser procesados como lo hemos visto en todas las clases anteriores. \n",
    "\n",
    "Lo más intuitivo sería pensar que para encontrar un documento reelevante para nuestra búsqueda, deberíamos contar la cantidad de aparciones de cada término en nuestra búsqueda.\n",
    "Para analizar de mejor forma esto, descompondremos nuestra query.\n",
    "\n",
    "$Q$ = \"profesores de ESCOM\" = [\"profesores\", \"de\", \"ESCOM\"]\n",
    "\n",
    "Si descomponemos nuestra *query* tendremos esto:\n",
    "\n",
    "$q_{0}$= \"profesores\"\n",
    "\n",
    "$q_{1}$= \"de\"\n",
    "\n",
    "$q_{2}$= \"ESCOM\"\n",
    "\n",
    "Si buscamos la frecuencia de nuestras palabras en la query en un documento *(corpus)*, obtendríamos algo similar a esto:\n",
    "\n",
    "$f(q_{0}) = 3$\n",
    "\n",
    "$f(q_{1}) = 244$\n",
    "\n",
    "$f(q_{2}) = 1$\n",
    "\n",
    "Como podemos ver en el ejemplo, la palabra \"de\" tiene muchas apariciones en el *corpus* de forma que contar la frecuencia bruta o probabilistica no es una buena opción ya que las palabras realmente significantes de nuestro texto que son *\"profesores\"* y *\"ESCOM\"*, y *\"de\"* realmente no es una palabra significante para nuestro texto.\n",
    "\n",
    "Por este motivo es que remover las *stopwords* de un corpus forma parte de la normalización del mismo. Sin embargo, siempre habrá palabras no consideradas como *stopwords* y que aún así no aporten ningún valor real a nuestra búsqueda.\n",
    "\n",
    "Para solventar esto, debemos encontrar una forma de ***penalizar*** a las palabras como *de*, una palabra sin mucho aporte al texto es fácil de identificar porque suelen ser muy frecuentes como lo vimos en el ejemplo anterior. De forma que si una palabra es altamente frecuente deberemos penalizarla para quitarle reelevancia y que palabras realmente importantes tomen un mayor protagonism. \n",
    "\n",
    "Aquí es donde **BM25** nos ayudará, ya que nos dará una forma puntuar la relación entre una *query* $Q$ y un *documento* $D$.\n",
    "\n",
    "### El modelo BM25\n",
    "Este modelo nos permitrá analizar una query y un documento basandose en 3 factores:\n",
    "- Frecuencia de los Términos (*Term Frequency* o ***TF***)\n",
    "- Frecuencia Inversa de los Términos en el Documento (*Inverse Document Frequency Term* o ***IDF***)\n",
    "- Longitud del Documento (*Documento Length* o $|D|$)\n",
    "\n",
    "La puntuación BM25 de una *query* $Q$ con un *documento* $D$ se representa como $score(D,Q)$, pero tal como vimos anteriormente una query puede terner más de una palabra, por lo que la puntuación de una query, será igual a la suma de sus puntuaciones en cada palabra. Es decir:\n",
    "\n",
    "$$\n",
    "    score(D,Q) = score(D,q_{0}) + score(D,q_{1}) + \\dots + score(D,q_{n}) = \\sum_{i=0}^{n}{score(D,q_{i})}\n",
    "$$\n",
    "\n",
    "Para obtener cada $score(D,q_{i})$, deberemos medir nuestros 3 factores.\n",
    "\n",
    "#### Frecuencia de los Términos\n",
    "La **TF** mide la cantidad de apariciones de nuestra palabra $q_{i}$ en nuestro documento. Y lo representamos matemáticamente como $f(q_{i},D)$\n",
    "\n",
    "#### Frecuencia Inversa de los Términos en el Documento\n",
    "Es la función de ***penalización*** que ocuparemos y está representada como:\n",
    "$$\n",
    "IDF(q_{i}) = \\log{\\dfrac{N-docs(q_{i})+0.5}{docs(q_{i})+0.5}}\n",
    "$$\n",
    "\n",
    "Donde $N$ es la total cantidad de documentos que tenemos en toda la búsqueda. Es decir si estamos realizando una *query* entre 300 documentos, entonces $N=300$.\n",
    "$docs(q_{i})$ nos devuelve la cantidad de documentos en las que nuestra palabra $q_{i}$ aparece al menos una vez. \n",
    "\n",
    "A esta función se le conoce como la *frecuencia inversa* del término $q_{i}$ en el documento $D$\n",
    "\n",
    "#### Longitud del Documento\n",
    "Este factor nos ayuda a aportar mayor relevancia a un documento que a otro basandonos la longitud de un documento ya que, por ejemplo, si tuvieramos un documento con la palabra *comida* que aparece 10 veces y el documento tiene una longitud de 200 palabras, es muy probable que el documento sea altamente reelevante para nuestra búsqueda. Pero si la palabra *comida* apareciera 15 veces en un documento con una longitud de 100,000 palabras, es altamente probable que el documento no tenga tanta relevancia para nuestra busqueda dado que es probable que la palabra se haya utilizado sin neesidad de que el tema central del documento esté relacionado a la comida. \n",
    "\n",
    "Para lograr esto si tuvieramos $N$ documentos, dividiremos la longitud de nuestro texto $|D_{j}|$ entre el promedio de la longitud de nuestros documentos $avgdl = \\dfrac{\\sum_{j=0}^{N}{|D_{j}|}}{N}$\n",
    "\n",
    "Por lo que nuestra formula quedaría como $\\dfrac{|D_{j}|}{avgdl}$\n",
    "\n",
    "### Fórmula\n",
    "\n",
    "La formula del modelo BM25 finalmente quedaría como:\n",
    "\n",
    "$$\n",
    "score(D,Q) = \\sum_{i=1}^{n}{ IDF(q_{i}) * \\dfrac{ f(q_{i},D) * (k_{1}+1) }{ f(q_{i},D) + k_{1} * (1-b+b * \\dfrac{|D|}{avgdl}) } }\n",
    "$$\n",
    "\n",
    "$k_{1}$ y $b$ son parámetros que varían respecto a la colección de documentos con la que estemos trabajando, es decir si nuestra colección de documentos es de artículos científicos, nuestra $k_{1}$ y $b$ podrían ser diferentes a las utilizadas en una colección de documentos con recetas de cocina, ya que estos parámetros nos permitirán mejorar la puntuación otorgada a un documento en su cada caso específico. \n",
    "\n",
    "Sin embargo, si estuviesemos hablando de una búsqueda *general*, es decir en una colección no específica de datos, se han hecho muchos estudios al respecto y se ha convergido en valores de $k \\in [1.2, 2.0]$ y $b = 0.75$ como los valores que mejor puntuarán nuestro documento respecto a nuestra *query*\n",
    "\n",
    "### Resultados\n",
    "\n",
    "Ahora que tenemos nuestra función para puntuar una *query* y un *documento* $D$, deberemos calcular la puntuación de nuestra *query* con todos los documentos disponibles, y luego ordenarlos de mayor a menor, donde el documento con mayor puntuación deberá ser el mas relevante para nuestra query.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
