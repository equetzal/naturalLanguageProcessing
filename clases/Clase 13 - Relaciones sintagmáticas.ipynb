{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 13\n",
    "- **Alumna:** Enya Quetzalli Gómez Rodríguez *(Eduardo Gómez Rodríguez)*\n",
    "- **Profesora:** Olga Kolesnikova\n",
    "- **Escuela:** Escuela Superior de Cómputo del IPN\n",
    "- **Grupo:** 3CV9\n",
    "- **Semestre:** 2020/2\n",
    "    \n",
    "## Relaciones sintagmáticas\n",
    "\n",
    "Las relaciones sintagmáticas, son la forma en la que se relacionan las partes una sentencia en el lenguaje. Es decir, para expresanos creamos oraciones como por ejemplo *\"Anita lava la tina*, y con ello nos encontramos con una estructura de *sujeto* + *verbo* + *artículo determinado* + *sustantivo*. Tan solo en español contamos con:\n",
    "- Artículo\n",
    "- Sustantivo\n",
    "- Pronombre\n",
    "- Adjetivo\n",
    "- Verbo\n",
    "- Adverbio\n",
    "- Preposición\n",
    "- Conjunción \n",
    "- Interjección\n",
    "\n",
    "La forma en la cual utilizamos estas palabras para formar oraciones y sentencias se le llama **relaciones sintagmáticas**.\n",
    "Si no siguieramos las relaciones sintagmáticas, formaríamos oraciones sin sentido, por ejemplo *\"la lava tina anita\"*, no tiene sentido. Es por ello que para análisis del lenguaje natural es necesario poder analisar estas relaciones para poder comprender sentencias. \n",
    "\n",
    "### Etiquetado\n",
    "El etiquetado (**tagging** *en inglés*), es el primer paso a dar para el análisis de relaciones sintagmáticas, y consiste en poder clasificar una palabra en el tipo de palabra que juega en las relaciones sintagmáticas. \n",
    "\n",
    "NLTK nos provee de algunas herramientas para poder hacer tagging en inglés, veamos un rápido ejemplo de como funcionaría el etiquetado en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'plain', 'is', 'flying', 'over', 'the', 'sky']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(\"The plain is flying over the sky\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('plain', 'NN'), ('is', 'VBZ'), ('flying', 'VBG'), ('over', 'IN'), ('the', 'DT'), ('sky', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "taggedTokens = nltk.pos_tag(tokens)\n",
    "print(taggedTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, ntlk nos provee de herramientas muy útiles para poder obtener un texto tokenizado.\n",
    "Otro ejemplo interesante es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'), ('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "taggedTokens = nltk.pos_tag(nltk.word_tokenize(\"They refuse to permit us to obtain the refuse permit\"))\n",
    "print(taggedTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo interesante de notar es que la palabra ***refuse*** aparece dos veces en el texto, sin embargo cuenta con diferente etiqueta dado que juega un papel diferente dentro de la oración. \n",
    "Es por ello que un sistema de *text-to-speech* debe utilizar etiquetado **POS** para cumplir sus funciones de forma coherente.\n",
    "\n",
    "### Etiquetado REGEX\n",
    "En muchas ocasiones, el etiquedo automatico de NLTK noe s muy bueno, ya que no etiqueta correctamente las palabras que buscamos, y es por ello que un etiquetado *regex* (Expresiones Regulares), nos pemiten trabajar con una mejor calidad de etiquetado.\n",
    "\n",
    "Veamos como podemos crear un etiquetador automático en español usando *regex*\n",
    "Primero crearemos una lista de patrones, en la que indicaremos mediante una tupla la expresión regular seguido de la etiqueta que se le asignará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "        (r'.*o$', 'n'),  # noun masculine singular\n",
    "        (r'.*os$', 'n'), # noun masculine plural\n",
    "        (r'.*a$', 'n'),  # noun femenine singular\n",
    "        (r'.*as$', 'n')  # noun femenine plural\n",
    "    ]\n",
    "regexTagger = nltk.RegexpTagger(patterns, nltk.DefaultTagger('s'))\n",
    "tokens = nltk.word_tokenize(\"Hola amigo, eres lo máximo\")\n",
    "taggedTokens = regexTagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hola', 'n'), ('amigo', 'n'), (',', 's'), ('eres', 's'), ('lo', 'n'), ('máximo', 'n')]\n"
     ]
    }
   ],
   "source": [
    "print(taggedTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver como es que Hol**a**, amig**o**, l**o** y máxim**o**, son etiquetados con la letra 'o' ya que cumplen con el *regex* adecuando, y aquellos desconocidos son etiquetados con *s* tal como lo definimos en nuestro *regexTagger*\n",
    "\n",
    "Podemos mejorar la calidad de nuestro etiquetado añadiento un UnigramTagger a nuestro tagger de expresiones *regex*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramTagger = nltk.UnigramTagger(nltk.corpus.cess_esp.tagged_sents(), None, regexTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hola', 'n'), ('amigo', 'ncms000'), (',', 'Fc'), ('eres', 'vsip2s0'), ('lo', 'da0ns0'), ('máximo', 'aq0ms0')]\n"
     ]
    }
   ],
   "source": [
    "taggedTokens = unigramTagger.tag(tokens)\n",
    "print(taggedTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos obsersevar, podemos realizar un buen etiquedado de nuestros tokens mediante el uso de de backoff taggers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
