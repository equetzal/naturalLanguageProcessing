{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 16\n",
    "- **Alumna:** Enya Quetzalli Gómez Rodríguez *(Eduardo Gómez Rodríguez)*\n",
    "- **Profesora:** Olga Kolesnikova\n",
    "- **Escuela:** Escuela Superior de Cómputo del IPN\n",
    "- **Grupo:** 3CV9\n",
    "- **Semestre:** 2020/2\n",
    "\n",
    "## Selección de Articulos\n",
    "**Instrucciones:**\n",
    "   ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import math\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(txt):\n",
    "\tfrom bs4 import BeautifulSoup\n",
    "\treturn BeautifulSoup(txt,'lxml').get_text().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitText(txt):\n",
    "\treturn txt.replace('/', ' ').replace('.', ' ').replace('-', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteTrash(txt):\n",
    "\timport re\n",
    "\tgood = {'\\n'}\n",
    "\tfor i in \"abcdefghijklmnopqrstuvwxyz áéíóúñü\":\n",
    "\t\tgood.add(i)\n",
    "\tans = \"\"\n",
    "\tfor c in txt:\n",
    "\t\tif c in good:\n",
    "\t\t\tans += c\n",
    "\treturn ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitToSentences(txt):\n",
    "    tokenizer = nltk.data.load('nltk:tokenizers/punkt/english.pickle')\n",
    "    return tokenizer.tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteStopwords(txt):\n",
    "\tfrom nltk.corpus import stopwords\n",
    "\tans = []\n",
    "\tstp = stopwords.words()\n",
    "\tfor w in txt:\n",
    "\t\tif w not in stp:\n",
    "\t\t\tans.append(w)\n",
    "\treturn ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabulary(articles):\n",
    "    tokens = set()\n",
    "    for sentences in articles:\n",
    "        for sent in sentences:\n",
    "            for token in sent:\n",
    "                tokens.add(token)\n",
    "    return sorted(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequencies(sentences, vocabulary):\n",
    "    tokens = dict()\n",
    "    \n",
    "    for token in vocabulary:\n",
    "        tokens[token] = 0\n",
    "    \n",
    "    for sent in sentences:\n",
    "        for token in sent:\n",
    "            tokens[token] += 1\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGlobalFrequencies(articles, vocabulary):\n",
    "    tokens = dict()\n",
    "    \n",
    "    for token in vocabulary:\n",
    "        tokens[token] = 0\n",
    "    \n",
    "    for sentences in articles:\n",
    "        for sent in sentences:\n",
    "            for token in sent:\n",
    "                tokens[token] += 1\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContexts(wordList, windowSize=4):\n",
    "    contexts = dict()\n",
    "    index = 0\n",
    "    for index in range(len(wordList)):\n",
    "        word = wordList[index]\n",
    "        if word not in contexts:\n",
    "            contexts[word] = []\n",
    "        start = max(0, index - windowSize)\n",
    "        end = min(index + windowSize, len(wordList) - 1)\n",
    "        for i in range(start, end + 1):\n",
    "            if i != index:\n",
    "                contexts[word].append(wordList[i])\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFromJson(name):\n",
    "    import json\n",
    "    with open(\"./files/\"+name, 'r', encoding=\"utf8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpToJson(obj, name):\n",
    "    import json\n",
    "    with open(\"./files/\"+name, 'w', encoding=\"utf8\") as outfile:\n",
    "        json.dump(obj, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceWithStems(tokens):\n",
    "    ss = SnowballStemmer(\"spanish\")\n",
    "    stematized_tokens = []\n",
    "    for word in tokens:\n",
    "        stematized_tokens.append(ss.stem(word))\n",
    "    return stematized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacWithLemmas(tokens):\n",
    "    lemmas = loadFromJson(\"lemmatized_tokens_generate\")\n",
    "    lemmatized_tokens = []\n",
    "    for word in tokens:\n",
    "        if word in lemmas.keys():\n",
    "            lemmatized_tokens.append(lemmas[word])\n",
    "        else:\n",
    "            lemmatized_tokens.append(word)\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTagger():\n",
    "    patterns = [\n",
    "        (r'.*o$', 'n'),  # noun masculine singular\n",
    "        (r'.*os$', 'n'), # noun masculine plural\n",
    "        (r'.*a$', 'n'),  # noun femenine singular\n",
    "        (r'.*as$', 'n')  # noun femenine plural\n",
    "    ]\n",
    "    regexTagger = nltk.RegexpTagger(patterns, nltk.DefaultTagger('s'))\n",
    "    unigramTagger = nltk.UnigramTagger(nltk.corpus.cess_esp.tagged_sents(), None, regexTagger)\n",
    "    return unigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixTags(tokens, tokenTags):\n",
    "    taggedTokens = list()\n",
    "    for i in range(0,len(tokens)):\n",
    "        taggedTokens.append((tokens[i], tokenTags[i][1]))\n",
    "    return taggedTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSencences(sent, tagger):\n",
    "    sentences = []\n",
    "    for s in sent:\n",
    "        cleanSentence = deleteTrash(splitText(s))\n",
    "        normalizedTokens = deleteStopwords(nltk.word_tokenize(cleanSentence))\n",
    "        tokenTags = tagger.tag(normalizedTokens)\n",
    "        stematizedTokens = replaceWithStems(normalizedTokens)\n",
    "        tokens = mixTags(stematizedTokens, tokenTags)\n",
    "        sentences.append(tokens)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadArticles(org_txt):\n",
    "    tagger = getTagger()\n",
    "    arts = org_txt.split(\"<h3>\")[1:]\n",
    "    articles = list()\n",
    "    for art in arts:\n",
    "        sentences = splitToSentences(cleanHtml(art))\n",
    "        sentences = normalizeSencences(sentences, tagger)\n",
    "        articles.append(sentences)\n",
    "    return articles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./files/e961024.htm\", \"r\", encoding=\"utf8\")\n",
    "org_txt = f.read()\n",
    "f.close()\n",
    "\n",
    "articles = loadArticles(org_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = getVocabulary(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = dict()\n",
    "for i in range(len(articles)):\n",
    "    frequencies[i] = getFrequencies(articles[i], vocabulary)\n",
    "globalFrequencies = getGlobalFrequencies(articles,vocabulary) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obteniendo la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordFreq(target, frequency, vocabulary):\n",
    "    w = SnowballStemmer(\"spanish\").stem(target)\n",
    "    targetTokens = set()\n",
    "    for token in vocabulary:\n",
    "        if token[0] == w:\n",
    "            targetTokens.add(token)\n",
    "            \n",
    "    freq = 0\n",
    "    for token in targetTokens:\n",
    "        freq += frequency[token]\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTable(topics, articles, frequencies, globalFrequencies, vocabulary):\n",
    "    t = len(topics)\n",
    "    a = len(articles)\n",
    "    \n",
    "    total = dict()\n",
    "    for j in range(t):\n",
    "        total[j] = getWordFreq(topics[j], globalFrequencies, vocabulary)\n",
    "    \n",
    "    table = [[0 for j in range(t)] for i in range(a)]\n",
    "    for i in range(a):\n",
    "        for j in range(t):\n",
    "            inDoc = getWordFreq(topics[j], frequencies[i], vocabulary)\n",
    "            table[i][j] = inDoc/total[j]\n",
    "    return table    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTable(topics, articles, table):\n",
    "    with open(\"./p16_docs/table.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(F\"{' ':{5}}\")\n",
    "        for j in range(len(topics)):\n",
    "            f.write(F\"{str(topics[j]):{21}}\")\n",
    "        f.write(F\"\\n\")\n",
    "        for i in range(len(articles)):\n",
    "            f.write(F\"{str(i):{5}}\")\n",
    "            for j in range(len(topics)):\n",
    "                f.write(F\"{str(table[i][j]):{20}} \")\n",
    "            f.write(F\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"gobierno\", \"política\", \"méxico\", \"tecnología\", \"crisis\"]\n",
    "table = getTable(topics,articles, frequencies, globalFrequencies, vocabulary)\n",
    "printTable(topics, articles, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gobierno             política             méxico               tecnología           crisis               \n",
      "0    0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "1    0.044444444444444446 0.027777777777777776 0.0                  0.0                  0.0                  \n",
      "2    0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "3    0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "4    0.0                  0.009259259259259259 0.0                  0.0                  0.2                  \n",
      "5    0.011111111111111112 0.046296296296296294 0.0053475935828877   0.04                 0.0                  \n",
      "6    0.011111111111111112 0.037037037037037035 0.026737967914438502 0.0                  0.0                  \n",
      "7    0.06666666666666667  0.06481481481481481  0.0                  0.0                  0.06666666666666667  \n",
      "8    0.044444444444444446 0.027777777777777776 0.0053475935828877   0.0                  0.0                  \n",
      "9    0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "10   0.0                  0.0                  0.0053475935828877   0.0                  0.0                  \n",
      "11   0.0                  0.0                  0.0                  0.04                 0.0                  \n",
      "12   0.03333333333333333  0.018518518518518517 0.0053475935828877   0.0                  0.0                  \n",
      "13   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "14   0.03333333333333333  0.009259259259259259 0.0                  0.0                  0.0                  \n",
      "15   0.044444444444444446 0.09259259259259259  0.0053475935828877   0.04                 0.0                  \n",
      "16   0.022222222222222223 0.027777777777777776 0.0053475935828877   0.0                  0.0                  \n",
      "17   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "18   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "19   0.044444444444444446 0.027777777777777776 0.0053475935828877   0.0                  0.0                  \n",
      "20   0.0                  0.0                  0.0053475935828877   0.0                  0.0                  \n",
      "21   0.0                  0.0                  0.09090909090909091  0.12                 0.0                  \n",
      "22   0.0                  0.0                  0.016042780748663103 0.04                 0.0                  \n",
      "23   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "24   0.05555555555555555  0.046296296296296294 0.016042780748663103 0.0                  0.0                  \n",
      "25   0.011111111111111112 0.1388888888888889   0.0481283422459893   0.08                 0.0                  \n",
      "26   0.011111111111111112 0.009259259259259259 0.0                  0.0                  0.0                  \n",
      "27   0.0                  0.0                  0.0053475935828877   0.04                 0.0                  \n",
      "28   0.0                  0.0                  0.016042780748663103 0.04                 0.0                  \n",
      "29   0.06666666666666667  0.009259259259259259 0.0106951871657754   0.0                  0.1                  \n",
      "30   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "31   0.044444444444444446 0.0                  0.10695187165775401  0.0                  0.03333333333333333  \n",
      "32   0.011111111111111112 0.0                  0.03208556149732621  0.0                  0.1                  \n",
      "33   0.011111111111111112 0.06481481481481481  0.0481283422459893   0.04                 0.13333333333333333  \n",
      "34   0.0                  0.0                  0.03208556149732621  0.0                  0.0                  \n",
      "35   0.044444444444444446 0.037037037037037035 0.0053475935828877   0.0                  0.06666666666666667  \n",
      "36   0.0                  0.0                  0.0                  0.24                 0.0                  \n",
      "37   0.06666666666666667  0.0                  0.053475935828877004 0.0                  0.0                  \n",
      "38   0.011111111111111112 0.0                  0.016042780748663103 0.08                 0.06666666666666667  \n",
      "39   0.0                  0.0                  0.053475935828877004 0.0                  0.0                  \n",
      "40   0.08888888888888889  0.0                  0.08021390374331551  0.0                  0.0                  \n",
      "41   0.0                  0.0                  0.0106951871657754   0.0                  0.0                  \n",
      "42   0.011111111111111112 0.0                  0.0053475935828877   0.04                 0.0                  \n",
      "43   0.022222222222222223 0.0                  0.0                  0.0                  0.0                  \n",
      "44   0.011111111111111112 0.046296296296296294 0.0053475935828877   0.0                  0.0                  \n",
      "45   0.011111111111111112 0.009259259259259259 0.0053475935828877   0.0                  0.03333333333333333  \n",
      "46   0.0                  0.0                  0.0053475935828877   0.0                  0.0                  \n",
      "47   0.0                  0.018518518518518517 0.0                  0.0                  0.0                  \n",
      "48   0.0                  0.0                  0.016042780748663103 0.0                  0.0                  \n",
      "49   0.044444444444444446 0.0                  0.026737967914438502 0.0                  0.0                  \n",
      "50   0.011111111111111112 0.027777777777777776 0.0                  0.0                  0.1                  \n",
      "51   0.011111111111111112 0.009259259259259259 0.0                  0.0                  0.0                  \n",
      "52   0.0                  0.0                  0.016042780748663103 0.0                  0.0                  \n",
      "53   0.0                  0.018518518518518517 0.0053475935828877   0.0                  0.03333333333333333  \n",
      "54   0.011111111111111112 0.018518518518518517 0.0053475935828877   0.0                  0.0                  \n",
      "55   0.0                  0.0                  0.0                  0.04                 0.0                  \n",
      "56   0.0                  0.0                  0.0053475935828877   0.0                  0.0                  \n",
      "57   0.011111111111111112 0.009259259259259259 0.0                  0.0                  0.06666666666666667  \n",
      "58   0.044444444444444446 0.009259259259259259 0.0053475935828877   0.0                  0.0                  \n",
      "59   0.0                  0.018518518518518517 0.0106951871657754   0.0                  0.0                  \n",
      "60   0.0                  0.018518518518518517 0.0                  0.0                  0.0                  \n",
      "61   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "62   0.0                  0.046296296296296294 0.0                  0.0                  0.0                  \n",
      "63   0.0                  0.027777777777777776 0.0053475935828877   0.0                  0.0                  \n",
      "64   0.0                  0.009259259259259259 0.0053475935828877   0.0                  0.0                  \n",
      "65   0.0                  0.0                  0.09090909090909091  0.12                 0.0                  \n",
      "66   0.011111111111111112 0.0                  0.03208556149732621  0.0                  0.0                  \n",
      "67   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "68   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "69   0.0                  0.018518518518518517 0.0106951871657754   0.0                  0.0                  \n",
      "70   0.0                  0.0                  0.0053475935828877   0.0                  0.0                  \n",
      "71   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "72   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "73   0.022222222222222223 0.0                  0.026737967914438502 0.0                  0.0                  \n",
      "74   0.0                  0.0                  0.0                  0.0                  0.0                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tb = open(\"./p16_docs/table.txt\", \"r\", encoding=\"utf8\")\n",
    "tb_txt = tb.read()\n",
    "tb.close()\n",
    "print(tb_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
